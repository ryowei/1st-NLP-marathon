{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "cupoy_env",
      "language": "python",
      "name": "cupoy_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "D016_計數方法詞向量介紹_作業.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryowei/1st-NLP-marathon/blob/main/D016_%E8%A8%88%E6%95%B8%E6%96%B9%E6%B3%95%E8%A9%9E%E5%90%91%E9%87%8F%E4%BB%8B%E7%B4%B9_%E4%BD%9C%E6%A5%AD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HJXS69c_zjh"
      },
      "source": [
        "## 作業目標: 透過思考與回答以更加了解計數方法的詞向量"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIgGUYqy_zjo"
      },
      "source": [
        "### 請問詞庫手法會有什麼樣的優缺點？\n",
        "\n",
        "詞庫手法為創建包含大量字詞的詞庫，將相同意思字詞(同義字)或相似意思字詞(相似字)分類在相同群組。\n",
        "\n",
        "優點:\n",
        " - 較為精確的人工判斷分類結果的字詞，可觀測到字詞之間的上下關係，前後關係。\n",
        "\n",
        "缺點:\n",
        " - 建立詞庫需要大量人力與時間成本\n",
        " - 無法辨識新產生的詞 (ex：當我塑膠）\n",
        " - 須以人工更新與維護詞庫"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsAzR1_B_zjp"
      },
      "source": [
        "### 請問共現矩陣有什麼樣的優缺點？ \n",
        "\n",
        "根據分佈假說，相似的字詞會有類似的上下文，因此我們可以透過計數周圍(window)的字詞來表達特定字詞的向量。\n",
        "\n",
        "優點:\n",
        " - 觀測整個語料庫的所有詞彙，便在預測下一個字詞時較為近似實際字詞\n",
        "\n",
        "缺點:\n",
        " - 矩陣維度龐大，需要大量的內存\n",
        " - 對高頻詞效果較差（ex: “the apple“可能經常出現，但”the”跟”apple”的關聯性是不高的）,沒有反應詞與詞之間的關係"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n5LmrLM_zjp"
      },
      "source": [
        "### 請問為何需要對共現矩陣或PPMI進行SVD降維?\n",
        "\n",
        " - SVD 降維度： 主要是共現矩陣的內存空間太大，只要將重要的資訊提取出來即可，降低資料的雜訊。\n",
        " - PPMI ：由於共現矩陣在高頻詞下有缺陷，因此作轉換來反應兩兩字詞之間同時出現的機率有多高。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xHjyLuH_zjq"
      },
      "source": [
        "### 實作cosine similarity\n",
        "\n",
        "在比較兩個詞向量的相似度時可以使用cosine similarity:\n",
        "$$\n",
        "similarity(x,y) = \\frac{x \\cdot y}{||x||||y||} = \\frac{x_1y_1+...+x_ny_n}{\\sqrt{x_1^2+...+x_n^2}\\sqrt{y_1^2+...+y_n^2}}\n",
        "$$\n",
        "\n",
        "請實作cosine similarity並計算共現矩陣課程範例中you向量([0,1,0,0,0,0,0])與I([0,1,0,1,0,0,0])向量的相似度"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOOSOjTj_zjq",
        "outputId": "b523e113-c337-44e8-cb96-69ca7d3038e7"
      },
      "source": [
        "import numpy as np\n",
        "I = np.array([0,1,0,0,0,0,0])\n",
        "You = np.array([0,1,0,1,0,0,0])\n",
        "\n",
        "def cos_similarity(x, y, eps=1e-8):\n",
        "    ### your code ###\n",
        "    nx = x / (sum(x**2))**0.5\n",
        "    ny = y / (sum(y**2))**0.5\n",
        "    res = np.dot(nx,ny)\n",
        "    return res\n",
        "\n",
        "print(f\"Similarity: {cos_similarity(I, You)}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity: 0.7071067811865475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rqi9qQDzCUCT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}